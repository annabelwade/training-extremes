{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from earth2studio.io import ZarrBackend\n",
    "from SFNO_update import SFNO\n",
    "import earth2studio.data as data\n",
    "from earth2studio.models.auto import Package\n",
    "from utils import filename_to_year, datetime_range, open_hdf5\n",
    "from deterministic_update import deterministic\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import xarray as xr\n",
    "from typing import List\n",
    "import shutil\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_hpc_device():\n",
    "    \"\"\"\n",
    "    Robustly selects the primary compute device and applies architecture-specific\n",
    "    optimizations (TF32) only when the GPU can support this.\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"WARNING: CUDA is not available. Falling back to CPU.\")\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "    # Setup based on available resources\n",
    "    #     the 'primary' device is always logical index 0.\n",
    "    device_index = 0 \n",
    "    device = torch.device(f\"cuda:{device_index}\")\n",
    "    torch.cuda.set_device(device)\n",
    "    \n",
    "    num_devices = torch.cuda.device_count()\n",
    "    gpu_name = torch.cuda.get_device_name(device)\n",
    "    \n",
    "    # Architecture-Specific Optimizations\n",
    "    # Get Compute Capability (Major, Minor)\n",
    "    capability = torch.cuda.get_device_capability(device)\n",
    "    major_version = capability[0]\n",
    "    \n",
    "    # TF32 is supported on Ampere (8.0) and newer (Hopper is 9.0)\n",
    "    if major_version >= 8:\n",
    "        print(f\"[{gpu_name}] Architecture {major_version}.x detected: Enabling TF32.\")\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "    else:\n",
    "        print(f\"[{gpu_name}] Architecture {major_version}.x detected: TF32 not supported. Using standard FP32.\")\n",
    "        # Ensure it is false for older cards\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "\n",
    "    # Report Status\n",
    "    print(f\"--- HPC Device Context ---\")\n",
    "    print(f\"Total Visible GPUs: {num_devices}\")\n",
    "    print(f\"Active Device:      {device} ({gpu_name})\")\n",
    "    print(f\"Memory (VRAM):      {torch.cuda.get_device_properties(device).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"--------------------------\")\n",
    "    \n",
    "    return device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NVIDIA H200 NVL] Architecture 9.x detected: Enabling TF32.\n",
      "--- HPC Device Context ---\n",
      "Total Visible GPUs: 1\n",
      "Active Device:      cuda:0 (NVIDIA H200 NVL)\n",
      "Memory (VRAM):      150.11 GB\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "device = setup_hpc_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORIGINAL SFNO SCRIPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from earth2studio.io import ZarrBackend\n",
    "from SFNO_update import SFNO\n",
    "import earth2studio.data as data\n",
    "from earth2studio.models.auto import Package\n",
    "from utils import filename_to_year, datetime_range, open_hdf5\n",
    "from deterministic_update import deterministic\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import xarray as xr\n",
    "from typing import List\n",
    "import shutil\n",
    "import sys\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_id = int(os.environ.get(\"CUDA_VISIBLE_DEVICES\", 0))\n",
    "    torch.cuda.set_device(gpu_id)\n",
    "import time\n",
    "time_start = time.time()\n",
    "\n",
    "############# Double check these before running the script #############\n",
    "slurm_select = int(sys.argv[1]) # I run this with 3 slurm array tasks so checkpoint 1-35, 36-70, 71-90 run at the same time\n",
    "\n",
    "#select start datetime and n_steps, each n_step = 6hrs\n",
    "start_datetime = '2019-03-22T00:00:00' \n",
    "variables_to_select = ['msl', 'tcwv'] #Only save selected variables - it slows down inference SIGNIFICANTLY to save all 74 variables\n",
    "experiment_number = 5\n",
    "n_steps = 12\n",
    "\n",
    "boring = False\n",
    "ema = False\n",
    "\n",
    "# Create the inference name based on the start datetime and number of steps\n",
    "inference_name = datetime.fromisoformat(start_datetime).strftime(\"%Y_%m_%dT%H\")+'_nsteps'+str(n_steps)\n",
    "data_create_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Initialize_data/Initialize_\"+inference_name+\".nc\"\n",
    "\n",
    "############# Double check these before running the script #############\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the final datetime based from the start datetime and number of steps\n",
    "final_datetime = (datetime.fromisoformat(start_datetime) + timedelta(hours = int(n_steps*6))).isoformat() \n",
    "\n",
    "\n",
    "if os.path.exists(data_create_fp):\n",
    "    print(f\"Data already preprocessed: {data_create_fp}\")\n",
    "else:\n",
    "    sys.exit(f\"Data not found use Create_Initial_Data.ipynb to create: {data_create_fp}\")\n",
    "\n",
    "#make this xarray into a dataarray file for earth2studio\n",
    "initial_data = data.DataArrayFile(data_create_fp)\n",
    "\n",
    "time_1 = time.time()\n",
    "print(f\"Data loaded in {time_1 - time_start:.2f} seconds\")\n",
    "\n",
    "if slurm_select == 0:\n",
    "\n",
    "    for n_epoch in np.arange(1,36,1):\n",
    "        time_2 = time.time()\n",
    "        if boring:\n",
    "            # Create the final datetime string in the desired format\n",
    "            results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecasts_Boring/\"+final_datetime[:10].replace(\"-\", \"_\")+\"/Checkpoint\"+str(n_epoch)+\"_\"+inference_name+'.nc'\n",
    "        else:# Create the final datetime string in the desired format\n",
    "            if ema:\n",
    "                results_out_fp = f\"/barnes-engr-scratch2/C837824079/Experiment{str(experiment_number)}/Forecast/EMA_9/Checkpoint{n_epoch}_{inference_name}.nc\"\n",
    "            else:\n",
    "                results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecast/Checkpoint\"+str(n_epoch)+\"_\"+inference_name+'.nc'\n",
    "        # Check if the results file already exists\n",
    "        if os.path.exists(results_out_fp):\n",
    "            print(f\"Results file {results_out_fp} already exists. Skipping to next epoch.\")\n",
    "            continue  # Skip the rest of the loop and go to the next iteration\n",
    "        else:\n",
    "            os.makedirs(os.path.dirname(results_out_fp), exist_ok=True)\n",
    "\n",
    "            load_dotenv()  \n",
    "\n",
    "            # Make temporary folder with all the metadata in it.\n",
    "\n",
    "            src_dir = \"/barnes-engr-scratch2/C837824079/Checkpoints_SFNO/sfno_linear_74chq_sc3_layers8_edim384_dt6h_wstgl2/v0.1.0-seed999/\"\n",
    "\n",
    "            # Load the model package from storage\n",
    "            model_package = Package(src_dir, cache = False)\n",
    "            model = SFNO.load_model(model_package, checkpoint_name = 'ckpt_mp0_epoch'+str(n_epoch)+'.tar', EMA = ema)\n",
    "\n",
    "            # Create the IO handler, store in memory\n",
    "            io = ZarrBackend()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # run inference\n",
    "                io = deterministic([start_datetime], n_steps, model, initial_data, io, variables_list=variables_to_select)\n",
    "\n",
    "            print(io.root.tree())\n",
    "\n",
    "\n",
    "            # save results to netcdf\n",
    "            # Open the Zarr group from the in-memory store using xarray\n",
    "            ds = xr.open_zarr(io.root.store)\n",
    "\n",
    "            # Convert the 'time' coordinate in ds to datetime64 format\n",
    "            ds[\"time\"] = ds[\"time\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "            # Convert lead_time from nanoseconds to timedelta64[ns]\n",
    "            base_time = ds[\"time\"].values  # shape (n_time,)\n",
    "            lead_timedelta = ds[\"lead_time\"].values.astype(\"timedelta64[ns]\")  # shape (n_lead_time,)\n",
    "            # Broadcast to 2D: (time, lead_time)\n",
    "            valid_timesteps = (base_time[:, None] + lead_timedelta[None, :]).flatten() \n",
    "            # Drop the old lead_time coordinate\n",
    "            ds = ds.drop_vars(\"lead_time\")\n",
    "\n",
    "            # Assume ds has dimensions (time, lead_time, lat, lon) and only one time\n",
    "            initial_time = str(ds[\"time\"].values[0])  # Save the initial time as a string\n",
    "            # Remove the time dimension by selecting the first (and only) time\n",
    "            ds = ds.isel(time=0).drop_vars(\"time\")\n",
    "            # Add the initial time as a global attribute\n",
    "            ds.attrs[\"initial_time\"] = initial_time\n",
    "\n",
    "            # Create valid_time by adding lead_timedelta to base_time\n",
    "            ds = ds.rename({\"lead_time\": \"valid_time\"})\n",
    "            # Assign valid_time as a coordinate\n",
    "            ds = ds.assign_coords(valid_time=((\"valid_time\",), valid_timesteps))\n",
    "\n",
    "            # only save the final time step\n",
    "            if np.datetime64(final_datetime) in ds[\"valid_time\"].values:\n",
    "                ds = ds.sel(valid_time=[final_datetime])\n",
    "                ds = ds[variables_to_select]\n",
    "                ds.to_netcdf(results_out_fp, mode=\"w\", format=\"NETCDF4\")\n",
    "                print(f\"Results saved to {results_out_fp}\")\n",
    "            else:\n",
    "                print(f\"ERROR: final_datetime {final_datetime} not found in ds['valid_time']. No file saved.\")\n",
    "\n",
    "\n",
    "            #some cleanup\n",
    "            torch.cuda.empty_cache()\n",
    "            del model_package\n",
    "            del model\n",
    "            del io\n",
    "            del ds\n",
    "            gc.collect()\n",
    "            time_3 = time.time()\n",
    "            print(f\"Epoch {n_epoch} done: {time_3 - time_2:.2f} seconds\")\n",
    "\n",
    "elif slurm_select == 1:\n",
    "\n",
    "    for n_epoch in np.arange(36,71,1):\n",
    "        time_2 = time.time()\n",
    "        if boring:\n",
    "            # Create the final datetime string in the desired format\n",
    "            results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecasts_Boring/\"+final_datetime[:10].replace(\"-\", \"_\")+\"/Checkpoint\"+str(n_epoch)+\"_\"+inference_name+'.nc'\n",
    "        else:# Create the final datetime string in the desired format\n",
    "            if ema:\n",
    "                results_out_fp = f\"/barnes-engr-scratch2/C837824079/Experiment{str(experiment_number)}/Forecast/EMA_9/Checkpoint{n_epoch}_{inference_name}.nc\"         \n",
    "            else:\n",
    "                results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecast/Checkpoint\"+str(n_epoch)+\"_\"+inference_name+'.nc'\n",
    "\n",
    "        # Check if the results file already exists\n",
    "        if os.path.exists(results_out_fp):\n",
    "            print(f\"Results file {results_out_fp} already exists. Skipping to next epoch.\")\n",
    "            continue  # Skip the rest of the loop and go to the next iteration\n",
    "        else:\n",
    "            os.makedirs(os.path.dirname(results_out_fp), exist_ok=True)\n",
    "\n",
    "            load_dotenv()  \n",
    "\n",
    "            # Make temporary folder with all the metadata in it.\n",
    "            src_dir = \"/barnes-engr-scratch2/C837824079/Checkpoints_SFNO/sfno_linear_74chq_sc3_layers8_edim384_dt6h_wstgl2/v0.1.0-seed999/\"\n",
    "\n",
    "            # Load the model package from storage\n",
    "            model_package = Package(src_dir, cache = False)\n",
    "            model = SFNO.load_model(model_package, checkpoint_name = 'ckpt_mp0_epoch'+str(n_epoch)+'.tar', EMA = ema)\n",
    "\n",
    "            # Create the IO handler, store in memory\n",
    "            io = ZarrBackend()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                # run inference\n",
    "                io = deterministic([start_datetime], n_steps, model, initial_data, io, variables_list=variables_to_select)\n",
    "\n",
    "            print(io.root.tree())\n",
    "\n",
    "\n",
    "            # save results to netcdf\n",
    "            # Open the Zarr group from the in-memory store using xarray\n",
    "            ds = xr.open_zarr(io.root.store)\n",
    "\n",
    "            # Convert the 'time' coordinate in ds to datetime64 format\n",
    "            ds[\"time\"] = ds[\"time\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "            # Convert lead_time from nanoseconds to timedelta64[ns]\n",
    "            base_time = ds[\"time\"].values  # shape (n_time,)\n",
    "            lead_timedelta = ds[\"lead_time\"].values.astype(\"timedelta64[ns]\")  # shape (n_lead_time,)\n",
    "            # Broadcast to 2D: (time, lead_time)\n",
    "            valid_timesteps = (base_time[:, None] + lead_timedelta[None, :]).flatten() \n",
    "            # Drop the old lead_time coordinate\n",
    "            ds = ds.drop_vars(\"lead_time\")\n",
    "\n",
    "            # Assume ds has dimensions (time, lead_time, lat, lon) and only one time\n",
    "            initial_time = str(ds[\"time\"].values[0])  # Save the initial time as a string\n",
    "            # Remove the time dimension by selecting the first (and only) time\n",
    "            ds = ds.isel(time=0).drop_vars(\"time\")\n",
    "            # Add the initial time as a global attribute\n",
    "            ds.attrs[\"initial_time\"] = initial_time\n",
    "\n",
    "            # Create valid_time by adding lead_timedelta to base_time\n",
    "            ds = ds.rename({\"lead_time\": \"valid_time\"})\n",
    "            # Assign valid_time as a coordinate\n",
    "            ds = ds.assign_coords(valid_time=((\"valid_time\",), valid_timesteps))\n",
    "\n",
    "            # only save the final time step\n",
    "            if np.datetime64(final_datetime) in ds[\"valid_time\"].values:\n",
    "                ds = ds.sel(valid_time=[final_datetime])\n",
    "                ds = ds[variables_to_select]\n",
    "                ds.to_netcdf(results_out_fp, mode=\"w\", format=\"NETCDF4\")\n",
    "                print(f\"Results saved to {results_out_fp}\")\n",
    "            else:\n",
    "                print(f\"ERROR: final_datetime {final_datetime} not found in ds['valid_time']. No file saved.\")\n",
    "\n",
    "\n",
    "            #some cleanup\n",
    "            torch.cuda.empty_cache()\n",
    "            del model_package\n",
    "            del model\n",
    "            del io\n",
    "            del ds\n",
    "            gc.collect()\n",
    "            time_3 = time.time()\n",
    "            print(f\"Epoch {n_epoch} done: {time_3 - time_2:.2f} seconds\")\n",
    "\n",
    "elif slurm_select == 2:\n",
    "    for n_epoch in np.arange(1,21,1):\n",
    "        time_2 = time.time()\n",
    "        # Create the final datetime string in the desired format\n",
    "        if boring:\n",
    "            # Create the final datetime string in the desired format\n",
    "            results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecasts_Boring/\"+final_datetime[:10].replace(\"-\", \"_\")+\"/Checkpoint\"+str(n_epoch+70)+\"_\"+inference_name+'.nc'\n",
    "        else:# Create the final datetime string in the desired format\n",
    "            if ema:\n",
    "                results_out_fp = f\"/barnes-engr-scratch2/C837824079/Experiment{str(experiment_number)}/Forecast/EMA_9/Checkpoint{n_epoch+70}_{inference_name}.nc\"\n",
    "            else:\n",
    "                results_out_fp = \"/barnes-engr-scratch2/C837824079/Experiment\"+str(experiment_number)+\"/Forecast/Checkpoint\"+str(n_epoch+70)+\"_\"+inference_name+'.nc'\n",
    "\n",
    "       \n",
    "        # Check if the results file already exists\n",
    "        if os.path.exists(results_out_fp):\n",
    "            print(f\"Results file {results_out_fp} already exists. Skipping to next epoch.\")\n",
    "            continue  # Skip the rest of the loop and go to the next iteration\n",
    "        else:\n",
    "            os.makedirs(os.path.dirname(results_out_fp), exist_ok=True)\n",
    "\n",
    "            load_dotenv()  \n",
    "\n",
    "            # Make temporary folder with all the metadata in it.\n",
    "            src_dir = \"/barnes-engr-scratch2/C837824079/Checkpoints_SFNO/multistep_sfno_linear_74chq_sc3_layers8_edim384_dt6h_wstgl2/v0.1.0-seed999-multistep2/\"\n",
    "\n",
    "            # Load the model package from storage\n",
    "            model_package = Package(src_dir, cache = False)\n",
    "            model = SFNO.load_model(model_package, checkpoint_name = 'ckpt_mp0_epoch'+str(n_epoch)+'.tar', EMA = ema)\n",
    "\n",
    "            # Create the IO handler, store in memory\n",
    "            io = ZarrBackend()\n",
    "\n",
    "            print(f\"Running inference for {inference_name}\")\n",
    "            with torch.no_grad():\n",
    "                # run inference\n",
    "                io = deterministic([start_datetime], n_steps, model, initial_data, io, variables_list=variables_to_select)\n",
    "\n",
    "            # print(io.root.tree())\n",
    "\n",
    "            # save results to netcdf\n",
    "            # Open the Zarr group from the in-memory store using xarray\n",
    "            ds = xr.open_zarr(io.root.store)\n",
    "\n",
    "            # Convert the 'time' coordinate in ds to datetime64 format\n",
    "            ds[\"time\"] = ds[\"time\"].astype(\"datetime64[ns]\")\n",
    "\n",
    "            # Convert lead_time from nanoseconds to timedelta64[ns]\n",
    "            base_time = ds[\"time\"].values  # shape (n_time,)\n",
    "            lead_timedelta = ds[\"lead_time\"].values.astype(\"timedelta64[ns]\")  # shape (n_lead_time,)\n",
    "            # Broadcast to 2D: (time, lead_time)\n",
    "            valid_timesteps = (base_time[:, None] + lead_timedelta[None, :]).flatten() \n",
    "            # Drop the old lead_time coordinate\n",
    "            ds = ds.drop_vars(\"lead_time\")\n",
    "\n",
    "            # Assume ds has dimensions (time, lead_time, lat, lon) and only one time\n",
    "            initial_time = str(ds[\"time\"].values[0])  # Save the initial time as a string\n",
    "            # Remove the time dimension by selecting the first (and only) time\n",
    "            ds = ds.isel(time=0).drop_vars(\"time\")\n",
    "            # Add the initial time as a global attribute\n",
    "            ds.attrs[\"initial_time\"] = initial_time\n",
    "\n",
    "            # Create valid_time by adding lead_timedelta to base_time\n",
    "            ds = ds.rename({\"lead_time\": \"valid_time\"})\n",
    "            # Assign valid_time as a coordinate\n",
    "            ds = ds.assign_coords(valid_time=((\"valid_time\",), valid_timesteps))\n",
    "\n",
    "            # only save the final time step\n",
    "            if np.datetime64(final_datetime) in ds[\"valid_time\"].values:\n",
    "                ds = ds.sel(valid_time=[final_datetime])\n",
    "                ds = ds[variables_to_select]\n",
    "                ds.to_netcdf(results_out_fp, mode=\"w\", format=\"NETCDF4\")\n",
    "                print(f\"Results saved to {results_out_fp}\")\n",
    "            else:\n",
    "                print(f\"ERROR: final_datetime {final_datetime} not found in ds['valid_time']. No file saved.\")\n",
    "\n",
    "\n",
    "            #some cleanup\n",
    "            torch.cuda.empty_cache()\n",
    "            del model_package\n",
    "            del model\n",
    "            del io\n",
    "            del ds\n",
    "            gc.collect()\n",
    "            time_3 = time.time()\n",
    "            print(f\"Epoch {n_epoch+70} done: {time_3 - time_2:.2f} seconds\")\n",
    "\n",
    "else:\n",
    "    sys.exit(\"Invalid slurm_select value. Please use 0, 1, or 2.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth2studio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
