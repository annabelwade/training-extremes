#!/bin/bash -l

# Send an email when the job finishes or if it is aborted (by default no email is sent).
#$ -m ea

# Give job a name
#$ -N example_inference

# Combine output and error files into a single file
#$ -j y

# Set SCC project
#$ -P eb-general

# Request 4 CPUs
#$ -pe omp 4

# Request 1 GPU 
#$ -l gpus=1

# Specify the minimum GPU compute capability. 
#$ -l gpu_c=7.0

# Keep track of information related to the current job
echo "=========================================================="
echo "Start date : $(date)"
echo "Job name : $JOB_NAME"
echo "Job ID : $JOB_ID  $SGE_TASK_ID"
echo "=========================================================="

# As an example, use the academic-ml module to get Python with machine learning.
module load miniconda
conda activate earth2studio

cd /projectnb/eb-general/wade/sfno/inference/

echo "--- Node & Resource Diagnostics ---"
echo "Node Hostname: $(hostname)"
echo "Start Time:    $(date)"
echo "Using $NSLOTS CPU cores."

# Verifies total memory available on the node and current usage buffers.
free -h

# Shows the specific GPU ID assigned to YOU, Driver version, and VRAM.
echo "--- GPU Allocation ---"
nvidia-smi --query-gpu=name,pci.bus_id,driver_version,memory.total,memory.free,memory.used --format=csv

# Define a log file for resource usage
LOG_FILE="resource_usage_${JOB_ID}.log"
echo "Timestamp, CPU_User%, MEM_Used_MB, GPU_Util%, GPU_Mem_MB" > $LOG_FILE
# Logs GPU stats every 120 seconds to a file
nvidia-smi dmon -s put -d 120 -o T > $LOG_FILE & 
#     The ampersand runs this subshell in the background

python Inference_Example.py




