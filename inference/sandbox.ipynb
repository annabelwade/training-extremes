{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import Iterable, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import xarray as xr\n",
    "import earth2studio\n",
    "from earth2studio.data import DataArrayFile\n",
    "from earth2studio.io import ZarrBackend\n",
    "from earth2studio.models.auto import Package\n",
    "\n",
    "from earth2studio.run import deterministic\n",
    "from earth2studio.models.px import SFNO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.0rc0\n"
     ]
    }
   ],
   "source": [
    "print(earth2studio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class InferenceConfig:\n",
    "    \"\"\"Configuration container for running the inference script.\"\"\"\n",
    "\n",
    "    start: str\n",
    "    steps: int\n",
    "    init_data: Path\n",
    "    checkpoint_dir: Path\n",
    "    checkpoint_name: str\n",
    "    output: Path\n",
    "    variables: list[str] | None\n",
    "    ema: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit these defaults to set preferred settings when launching the\n",
    "# script without CLI arguments (e.g., from a batch script).\n",
    "DEFAULT_CONFIG = InferenceConfig(\n",
    "    start=\"2019-03-22T00:00:00\",\n",
    "    steps=12,\n",
    "    init_data=Path(\"/projectnb/eb-general/wade/sfno/inference_runs/Ian/Initialize_data/Initialize_2019_08_27T00_nsteps20.nc\"),\n",
    "    checkpoint_dir=Path(\"/projectnb/eb-general/shared_data/data/processed/FourCastNet_sfno/Checkpoints_SFNO/sfno_linear_74chq_sc3_layers8_edim384_dt6h_wstgl2/v0.1.0-seed999/\"), # TODO CHECK IF THIS PATH NEEDS TO HAVE ADDITIONAL DIRECTORY TO THE MULTISTEP OR NON MULTISTEP DIR + seed + training_checkpoints\n",
    "    checkpoint_name=\"ckpt_mp0_epoch1.tar\", # for now, the code will just grab best ckpt, not this one.\n",
    "    output=Path(\"/projectnb/eb-general/wade/sfno/inference_runs/sandbox/\"), # todo make this automated to just take the directory, not the full path+name\n",
    "    variables=['msl'],\n",
    "    ema=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_args(defaults: InferenceConfig, cli_args: Sequence[str] | None = None) -> InferenceConfig:\n",
    "    \"\"\"Parse CLI arguments while honoring editable in-file defaults.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    defaults : InferenceConfig\n",
    "        Baseline values to use when a flag is omitted. Edit ``DEFAULT_CONFIG``\n",
    "        to change these defaults without typing flags.\n",
    "    cli_args : Sequence[str] | None\n",
    "        Argument vector to parse. When ``None`` (the common case), argparse\n",
    "        inspects ``sys.argv``. Passing an explicit sequence is useful for\n",
    "        programmatic invocation.\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Run SFNO inference with earth2studio 0.10.x\")\n",
    "    parser.add_argument(\n",
    "        \"--start\",\n",
    "        default=defaults.start,\n",
    "        help=\"ISO8601 start datetime for the forecast (e.g. 2019-03-22T00:00:00)\",\n",
    "    )\n",
    "    parser.add_argument(\"--steps\", type=int, default=defaults.steps, help=\"Number of 6-hour steps to forecast\")\n",
    "    parser.add_argument(\"--init-data\", default=str(defaults.init_data), help=\"Path to the preprocessed initial state NetCDF\")\n",
    "    parser.add_argument(\"--checkpoint-dir\", default=str(defaults.checkpoint_dir), help=\"Directory containing the SFNO checkpoints\")\n",
    "    parser.add_argument(\n",
    "        \"--checkpoint-name\",\n",
    "        default=defaults.checkpoint_name,\n",
    "        help=\"Checkpoint file name inside the checkpoint directory\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--output\",\n",
    "        default=str(defaults.output),\n",
    "        help=\"Output NetCDF path for the final forecast timestep\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--variables\",\n",
    "        nargs=\"+\",\n",
    "        default=defaults.variables,\n",
    "        help=\"Optional list of variables to keep (defaults to all variables)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--ema\",\n",
    "        action=\"store_true\",\n",
    "        default=defaults.ema,\n",
    "        help=\"Load EMA weights instead of the standard checkpoint\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args(args=cli_args)\n",
    "\n",
    "    ### ADDITION:\n",
    "    args, unknown = parser.parse_known_args(args=cli_args)\n",
    "    ###\n",
    "\n",
    "    return InferenceConfig(\n",
    "        start=args.start,\n",
    "        steps=args.steps,\n",
    "        init_data=Path(args.init_data),\n",
    "        checkpoint_dir=Path(args.checkpoint_dir),\n",
    "        checkpoint_name=args.checkpoint_name,\n",
    "        output=Path(args.output),\n",
    "        variables=args.variables,\n",
    "        ema=args.ema,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _normalize_valid_times(ds: xr.Dataset, final_timestamp: np.datetime64) -> xr.Dataset:\n",
    "    \"\"\"Align the earth2studio ``time`` and ``lead_time`` axes to usable timestamps.\n",
    "\n",
    "    earth2studio returns forecasts with two axes: the initialization time (``time``)\n",
    "    and the offsets from that initialization (``lead_time``). To mirror the legacy\n",
    "    inference example, we compute the actual verification timestamps (``valid_time``),\n",
    "    attach them as coordinates, and extract the requested final forecast hour.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ds : xr.Dataset\n",
    "        Dataset returned by earth2studio after running inference.\n",
    "    final_timestamp : np.datetime64\n",
    "        Target forecast verification time to extract.\n",
    "    \"\"\"\n",
    "\n",
    "    ds = ds.copy()\n",
    "    ds[\"time\"] = ds[\"time\"].astype(\"datetime64[ns]\")\n",
    "    base_time = ds[\"time\"].values\n",
    "    lead_timedelta = ds[\"lead_time\"].values.astype(\"timedelta64[ns]\")\n",
    "    valid_timesteps = (base_time[:, None] + lead_timedelta[None, :]).flatten()\n",
    "\n",
    "    # Preserve the initial time as metadata while collapsing the time dimension.\n",
    "    initial_time = str(ds[\"time\"].values[0])\n",
    "    ds = ds.isel(time=0).drop_vars(\"time\")\n",
    "    ds.attrs[\"initial_time\"] = initial_time\n",
    "\n",
    "    ds = ds.rename({\"lead_time\": \"valid_time\"})\n",
    "    ds = ds.assign_coords(valid_time=((\"valid_time\",), valid_timesteps))\n",
    "\n",
    "    if final_timestamp not in ds[\"valid_time\"].values:\n",
    "        raise ValueError(\n",
    "            f\"Requested final datetime {final_timestamp} not found in forecast valid times: {ds['valid_time'].values!r}\"\n",
    "        )\n",
    "\n",
    "    return ds.sel(valid_time=[final_timestamp])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_model(package_dir: Path, \n",
    "                # checkpoint_name: str, ema: bool\n",
    "        ) -> torch.nn.Module:\n",
    "    model_package = Package(str(package_dir), cache=False)\n",
    "    return SFNO.load_model(model_package, \n",
    "    # checkpoint_name=checkpoint_name, EMA=ema\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run_inference(\n",
    "    start_datetime: datetime,\n",
    "    n_steps: int,\n",
    "    checkpoint_dir: Path,\n",
    "    checkpoint_name: str,\n",
    "    init_data_path: Path,\n",
    "    output_path: Path,\n",
    "    variables: Iterable[str] | None,\n",
    "    ema: bool,\n",
    ") -> None:\n",
    "    if not init_data_path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Initial data file {init_data_path} not found. Generate it before running inference.\"\n",
    "        )\n",
    "\n",
    "    initial_data = DataArrayFile(str(init_data_path))\n",
    "    model = _load_model(checkpoint_dir, \n",
    "    # checkpoint_name,  ema\n",
    "    )\n",
    "    # Since earth2studio is expecting config.json to be in training_checkpoints,\n",
    "\n",
    "    io = ZarrBackend()\n",
    "    with torch.no_grad():\n",
    "        io = deterministic([start_datetime.isoformat()], n_steps, model, initial_data, io, \n",
    "        # variables_list=variables\n",
    "        )\n",
    "\n",
    "    ds = xr.open_zarr(io.root.store)\n",
    "    final_datetime = start_datetime + timedelta(hours=6 * n_steps)\n",
    "    final_timestamp = np.datetime64(final_datetime)\n",
    "    final_ds = _normalize_valid_times(ds, final_timestamp)\n",
    "\n",
    "    if variables is not None:\n",
    "        final_ds = final_ds[variables]\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    final_ds.to_netcdf(output_path, mode=\"w\", format=\"NETCDF4\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cli_args: Sequence[str] | None = None, config: InferenceConfig | None = None) -> None:\n",
    "    \"\"\"Run inference using CLI args or a provided configuration.\n",
    "\n",
    "    When ``config`` is omitted, argparse consumes ``cli_args`` (or ``sys.argv``)\n",
    "    and fills in any missing values from ``DEFAULT_CONFIG``. To hard-code\n",
    "    settings for batch runs without passing flags, edit ``DEFAULT_CONFIG`` and\n",
    "    invoke the script without arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    cfg = config or _parse_args(DEFAULT_CONFIG, cli_args)\n",
    "    start_dt = datetime.fromisoformat(cfg.start)\n",
    "\n",
    "    _run_inference(\n",
    "        start_datetime=start_dt,\n",
    "        n_steps=cfg.steps,\n",
    "        checkpoint_dir=cfg.checkpoint_dir,\n",
    "        checkpoint_name=cfg.checkpoint_name,\n",
    "        init_data_path=cfg.init_data,\n",
    "        output_path=cfg.output,\n",
    "        variables=cfg.variables,\n",
    "        ema=cfg.ema,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-10 14:39:03.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mearth2studio.run\u001b[0m:\u001b[36mdeterministic\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mRunning simple workflow!\u001b[0m\n",
      "\u001b[32m2025-12-10 14:39:03.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mearth2studio.run\u001b[0m:\u001b[36mdeterministic\u001b[0m:\u001b[36m82\u001b[0m - \u001b[1mInference device: cpu\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"not all values found in index 'time'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(cli_args, config)\u001b[39m\n\u001b[32m     10\u001b[39m cfg = config \u001b[38;5;129;01mor\u001b[39;00m _parse_args(DEFAULT_CONFIG, cli_args)\n\u001b[32m     11\u001b[39m start_dt = datetime.fromisoformat(cfg.start)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43m_run_inference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_datetime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_dt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheckpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_data_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mema\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36m_run_inference\u001b[39m\u001b[34m(start_datetime, n_steps, checkpoint_dir, checkpoint_name, init_data_path, output_path, variables, ema)\u001b[39m\n\u001b[32m     22\u001b[39m io = ZarrBackend()\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     io = \u001b[43mdeterministic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart_datetime\u001b[49m\u001b[43m.\u001b[49m\u001b[43misoformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# variables_list=variables\u001b[39;49;00m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m ds = xr.open_zarr(io.root.store)\n\u001b[32m     29\u001b[39m final_datetime = start_datetime + timedelta(hours=\u001b[32m6\u001b[39m * n_steps)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/earth2studio/run.py:96\u001b[39m, in \u001b[36mdeterministic\u001b[39m\u001b[34m(time, nsteps, prognostic, data, io, output_coords, device)\u001b[39m\n\u001b[32m     93\u001b[39m     interp_to = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     94\u001b[39m     interp_method = \u001b[33m\"\u001b[39m\u001b[33mnearest\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m x, coords = \u001b[43mfetch_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprognostic_ic\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvariable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlead_time\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprognostic_ic\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlead_time\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterp_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterp_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterp_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterp_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m logger.success(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFetched data from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# sphinx - fetch data end\u001b[39;00m\n\u001b[32m    108\u001b[39m \n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# Set up IO backend\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/earth2studio/data/utils.py:106\u001b[39m, in \u001b[36mfetch_data\u001b[39m\u001b[34m(source, time, variable, lead_time, device, interp_to, interp_method)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m lead \u001b[38;5;129;01min\u001b[39;00m lead_time:\n\u001b[32m    105\u001b[39m     adjust_times = np.array([t + lead \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m time], dtype=\u001b[33m\"\u001b[39m\u001b[33mdatetime64[ns]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     da0 = \u001b[43msource\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjust_times\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    107\u001b[39m     da0 = da0.expand_dims(dim={\u001b[33m\"\u001b[39m\u001b[33mlead_time\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m1\u001b[39m}, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    108\u001b[39m     da0 = da0.assign_coords(lead_time=np.array([lead], dtype=\u001b[33m\"\u001b[39m\u001b[33mtimedelta64[ns]\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/earth2studio/data/xr.py:62\u001b[39m, in \u001b[36mDataArrayFile.__call__\u001b[39m\u001b[34m(self, time, variable)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m     44\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     45\u001b[39m     time: datetime | \u001b[38;5;28mlist\u001b[39m[datetime] | TimeArray,\n\u001b[32m     46\u001b[39m     variable: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | VariableArray,\n\u001b[32m     47\u001b[39m ) -> xr.DataArray:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Function to get data.\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     60\u001b[39m \u001b[33;03m        Loaded data array\u001b[39;00m\n\u001b[32m     61\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariable\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/xarray/core/dataarray.py:1717\u001b[39m, in \u001b[36mDataArray.sel\u001b[39m\u001b[34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[39m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msel\u001b[39m(\n\u001b[32m   1602\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1603\u001b[39m     indexers: Mapping[Any, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1607\u001b[39m     **indexers_kwargs: Any,\n\u001b[32m   1608\u001b[39m ) -> Self:\n\u001b[32m   1609\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a new DataArray whose data is given by selecting index\u001b[39;00m\n\u001b[32m   1610\u001b[39m \u001b[33;03m    labels along the specified dimension(s).\u001b[39;00m\n\u001b[32m   1611\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1715\u001b[39m \u001b[33;03m    Dimensions without coordinates: points\u001b[39;00m\n\u001b[32m   1716\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1717\u001b[39m     ds = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_temp_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1718\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1719\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mindexers_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1723\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1724\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._from_temp_dataset(ds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/xarray/core/dataset.py:2988\u001b[39m, in \u001b[36mDataset.sel\u001b[39m\u001b[34m(self, indexers, method, tolerance, drop, **indexers_kwargs)\u001b[39m\n\u001b[32m   2920\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns a new dataset with each array indexed by tick labels\u001b[39;00m\n\u001b[32m   2921\u001b[39m \u001b[33;03malong the specified dimension(s).\u001b[39;00m\n\u001b[32m   2922\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2985\u001b[39m \n\u001b[32m   2986\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2987\u001b[39m indexers = either_dict_or_kwargs(indexers, indexers_kwargs, \u001b[33m\"\u001b[39m\u001b[33msel\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2988\u001b[39m query_results = \u001b[43mmap_index_queries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2989\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtolerance\u001b[49m\n\u001b[32m   2990\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2992\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m drop:\n\u001b[32m   2993\u001b[39m     no_scalar_variables = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/xarray/core/indexing.py:201\u001b[39m, in \u001b[36mmap_index_queries\u001b[39m\u001b[34m(obj, indexers, method, tolerance, **indexers_kwargs)\u001b[39m\n\u001b[32m    199\u001b[39m         results.append(IndexSelResult(labels))\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         results.append(\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    203\u001b[39m merged = merge_sel_results(results)\n\u001b[32m    205\u001b[39m \u001b[38;5;66;03m# drop dimension coordinates found in dimension indexers\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# (also drop multi-index if any)\u001b[39;00m\n\u001b[32m    207\u001b[39m \u001b[38;5;66;03m# (.sel() already ensures alignment)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/projectnb/eb-general/wade/.conda/envs/earth2studio/lib/python3.12/site-packages/xarray/core/indexes.py:873\u001b[39m, in \u001b[36mPandasIndex.sel\u001b[39m\u001b[34m(self, labels, method, tolerance)\u001b[39m\n\u001b[32m    871\u001b[39m     indexer = get_indexer_nd(\u001b[38;5;28mself\u001b[39m.index, label_array, method, tolerance)\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(indexer < \u001b[32m0\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnot all values found in index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcoord_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    875\u001b[39m \u001b[38;5;66;03m# attach dimension names and/or coordinates to positional indexer\u001b[39;00m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(label, Variable):\n",
      "\u001b[31mKeyError\u001b[39m: \"not all values found in index 'time'\""
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRIPT: (before edits)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Example inference runner compatible with earth2studio 0.10.x.\n",
    "\n",
    "# This script mirrors the workflow from the legacy\n",
    "# ``inference/old_package_verisons/Inference_Example.py`` but updates the\n",
    "# imports and I/O handling to align with the newer earth2studio API. It loads\n",
    "# an SFNO checkpoint, runs deterministic inference starting from a provided\n",
    "# initial state, and writes the requested variables for the final forecast time\n",
    "# step to NetCDF.\n",
    "# \"\"\"\n",
    "# from __future__ import annotations\n",
    "\n",
    "# import argparse\n",
    "# from dataclasses import dataclass\n",
    "# from datetime import datetime, timedelta\n",
    "# from pathlib import Path\n",
    "# import sys\n",
    "# from typing import Iterable, Sequence\n",
    "\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import xarray as xr\n",
    "# from earth2studio.data import DataArrayFile\n",
    "# from earth2studio.io import ZarrBackend\n",
    "# from earth2studio.models.auto import Package\n",
    "\n",
    "# # # start with basic inference -- no edits to backend code \n",
    "# # # - using best ckpt and save all vars#\n",
    "\n",
    "# # # TODO ONCE RUNNING INFERENCE - CHECK HOW THESE FUNCTIONS HAVE CHANGED IN THE NEW API, AND WHETHER OUR EDITS NEED TO BE CHANGED \n",
    "# # from deterministic_update import deterministic # vars -- less important\n",
    "# # from SFNO_update import SFNO  # checkpoint access -- most important\n",
    "# # take really diligent notes -- specific package versions\n",
    "# # - get a yaml of the env with versions!!!\n",
    "\n",
    "\n",
    "# @dataclass\n",
    "# class InferenceConfig:\n",
    "#     \"\"\"Configuration container for running the inference script.\"\"\"\n",
    "\n",
    "#     start: str\n",
    "#     steps: int\n",
    "#     init_data: Path\n",
    "#     checkpoint_dir: Path\n",
    "#     checkpoint_name: str\n",
    "#     output: Path\n",
    "#     variables: list[str] | None\n",
    "#     ema: bool\n",
    "\n",
    "\n",
    "# # Edit these defaults to set preferred settings when launching the\n",
    "# # script without CLI arguments (e.g., from a batch script).\n",
    "# DEFAULT_CONFIG = InferenceConfig(\n",
    "#     start=\"2019-03-22T00:00:00\",\n",
    "#     steps=12,\n",
    "#     init_data=Path(\"/projectnb/eb-general/wade/sfno/inference_runs/Ian/Initialize_data/Initialize_2019_08_27T00_nsteps20.nc\"),\n",
    "#     checkpoint_dir=Path(\"/projectnb/eb-general/shared_data/data/processed/FourCastNet_sfno/Checkpoints_SFNO/sfno_linear_74chq_sc3_layers8_edim384_dt6h_wstgl2/v0.1.0-seed999/training_checkpoints/\"), # TODO CHECK IF THIS PATH NEEDS TO HAVE ADDITIONAL DIRECTORY TO THE MULTISTEP OR NON MULTISTEP DIR + seed + training_checkpoints\n",
    "#     checkpoint_name=\"ckpt_mp0_epoch1.tar\",\n",
    "#     output=Path(\"/projectnb/eb-general/wade/sfno/inference_runs/sandbox/\"), # todo  fill in with desired output path?? or make it just output to dir + filename\n",
    "#     variables=['msl'],\n",
    "#     ema=False,\n",
    "# )\n",
    "\n",
    "\n",
    "# def _parse_args(defaults: InferenceConfig, cli_args: Sequence[str] | None = None) -> InferenceConfig:\n",
    "#     \"\"\"Parse CLI arguments while honoring editable in-file defaults.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     defaults : InferenceConfig\n",
    "#         Baseline values to use when a flag is omitted. Edit ``DEFAULT_CONFIG``\n",
    "#         to change these defaults without typing flags.\n",
    "#     cli_args : Sequence[str] | None\n",
    "#         Argument vector to parse. When ``None`` (the common case), argparse\n",
    "#         inspects ``sys.argv``. Passing an explicit sequence is useful for\n",
    "#         programmatic invocation.\n",
    "#     \"\"\"\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"Run SFNO inference with earth2studio 0.10.x\")\n",
    "#     parser.add_argument(\n",
    "#         \"--start\",\n",
    "#         default=defaults.start,\n",
    "#         help=\"ISO8601 start datetime for the forecast (e.g. 2019-03-22T00:00:00)\",\n",
    "#     )\n",
    "#     parser.add_argument(\"--steps\", type=int, default=defaults.steps, help=\"Number of 6-hour steps to forecast\")\n",
    "#     parser.add_argument(\"--init-data\", default=str(defaults.init_data), help=\"Path to the preprocessed initial state NetCDF\")\n",
    "#     parser.add_argument(\"--checkpoint-dir\", default=str(defaults.checkpoint_dir), help=\"Directory containing the SFNO checkpoints\")\n",
    "#     parser.add_argument(\n",
    "#         \"--checkpoint-name\",\n",
    "#         default=defaults.checkpoint_name,\n",
    "#         help=\"Checkpoint file name inside the checkpoint directory\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--output\",\n",
    "#         default=str(defaults.output),\n",
    "#         help=\"Output NetCDF path for the final forecast timestep\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--variables\",\n",
    "#         nargs=\"+\",\n",
    "#         default=defaults.variables,\n",
    "#         help=\"Optional list of variables to keep (defaults to all variables)\",\n",
    "#     )\n",
    "#     parser.add_argument(\n",
    "#         \"--ema\",\n",
    "#         action=\"store_true\",\n",
    "#         default=defaults.ema,\n",
    "#         help=\"Load EMA weights instead of the standard checkpoint\",\n",
    "#     )\n",
    "\n",
    "#     args = parser.parse_args(args=cli_args)\n",
    "#     return InferenceConfig(\n",
    "#         start=args.start,\n",
    "#         steps=args.steps,\n",
    "#         init_data=Path(args.init_data),\n",
    "#         checkpoint_dir=Path(args.checkpoint_dir),\n",
    "#         checkpoint_name=args.checkpoint_name,\n",
    "#         output=Path(args.output),\n",
    "#         variables=args.variables,\n",
    "#         ema=args.ema,\n",
    "#     )\n",
    "\n",
    "\n",
    "# def _normalize_valid_times(ds: xr.Dataset, final_timestamp: np.datetime64) -> xr.Dataset:\n",
    "#     \"\"\"Align the earth2studio ``time`` and ``lead_time`` axes to usable timestamps.\n",
    "\n",
    "#     earth2studio returns forecasts with two axes: the initialization time (``time``)\n",
    "#     and the offsets from that initialization (``lead_time``). To mirror the legacy\n",
    "#     inference example, we compute the actual verification timestamps (``valid_time``),\n",
    "#     attach them as coordinates, and extract the requested final forecast hour.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     ds : xr.Dataset\n",
    "#         Dataset returned by earth2studio after running inference.\n",
    "#     final_timestamp : np.datetime64\n",
    "#         Target forecast verification time to extract.\n",
    "#     \"\"\"\n",
    "\n",
    "#     ds = ds.copy()\n",
    "#     ds[\"time\"] = ds[\"time\"].astype(\"datetime64[ns]\")\n",
    "#     base_time = ds[\"time\"].values\n",
    "#     lead_timedelta = ds[\"lead_time\"].values.astype(\"timedelta64[ns]\")\n",
    "#     valid_timesteps = (base_time[:, None] + lead_timedelta[None, :]).flatten()\n",
    "\n",
    "#     # Preserve the initial time as metadata while collapsing the time dimension.\n",
    "#     initial_time = str(ds[\"time\"].values[0])\n",
    "#     ds = ds.isel(time=0).drop_vars(\"time\")\n",
    "#     ds.attrs[\"initial_time\"] = initial_time\n",
    "\n",
    "#     ds = ds.rename({\"lead_time\": \"valid_time\"})\n",
    "#     ds = ds.assign_coords(valid_time=((\"valid_time\",), valid_timesteps))\n",
    "\n",
    "#     if final_timestamp not in ds[\"valid_time\"].values:\n",
    "#         raise ValueError(\n",
    "#             f\"Requested final datetime {final_timestamp} not found in forecast valid times: {ds['valid_time'].values!r}\"\n",
    "#         )\n",
    "\n",
    "#     return ds.sel(valid_time=[final_timestamp])\n",
    "\n",
    "\n",
    "# def _load_model(package_dir: Path, \n",
    "#                 # checkpoint_name: str, ema: bool\n",
    "#         ) -> torch.nn.Module:\n",
    "#     model_package = Package(str(package_dir), cache=False)\n",
    "#     return SFNO.load_model(model_package, \n",
    "#     # checkpoint_name=checkpoint_name, EMA=ema\n",
    "#     )\n",
    "\n",
    "\n",
    "# def _run_inference(\n",
    "#     start_datetime: datetime,\n",
    "#     n_steps: int,\n",
    "#     checkpoint_dir: Path,\n",
    "#     checkpoint_name: str,\n",
    "#     init_data_path: Path,\n",
    "#     output_path: Path,\n",
    "#     variables: Iterable[str] | None,\n",
    "#     ema: bool,\n",
    "# ) -> None:\n",
    "#     if not init_data_path.exists():\n",
    "#         raise FileNotFoundError(\n",
    "#             f\"Initial data file {init_data_path} not found. Generate it before running inference.\"\n",
    "#         )\n",
    "\n",
    "#     initial_data = DataArrayFile(str(init_data_path))\n",
    "#     model = _load_model(checkpoint_dir, \n",
    "#     # checkpoint_name, \n",
    "#         ema)\n",
    "\n",
    "#     io = ZarrBackend()\n",
    "#     with torch.no_grad():\n",
    "#         io = deterministic([start_datetime.isoformat()], n_steps, model, initial_data, io, \n",
    "#         # variables_list=variables\n",
    "#         )\n",
    "\n",
    "#     ds = xr.open_zarr(io.root.store)\n",
    "#     final_datetime = start_datetime + timedelta(hours=6 * n_steps)\n",
    "#     final_timestamp = np.datetime64(final_datetime)\n",
    "#     final_ds = _normalize_valid_times(ds, final_timestamp)\n",
    "\n",
    "#     if variables is not None:\n",
    "#         final_ds = final_ds[variables]\n",
    "\n",
    "#     output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "#     final_ds.to_netcdf(output_path, mode=\"w\", format=\"NETCDF4\")\n",
    "\n",
    "\n",
    "\n",
    "# def main(cli_args: Sequence[str] | None = None, config: InferenceConfig | None = None) -> None:\n",
    "#     \"\"\"Run inference using CLI args or a provided configuration.\n",
    "\n",
    "#     When ``config`` is omitted, argparse consumes ``cli_args`` (or ``sys.argv``)\n",
    "#     and fills in any missing values from ``DEFAULT_CONFIG``. To hard-code\n",
    "#     settings for batch runs without passing flags, edit ``DEFAULT_CONFIG`` and\n",
    "#     invoke the script without arguments.\n",
    "#     \"\"\"\n",
    "\n",
    "#     cfg = config or _parse_args(DEFAULT_CONFIG, cli_args)\n",
    "#     start_dt = datetime.fromisoformat(cfg.start)\n",
    "\n",
    "#     _run_inference(\n",
    "#         start_datetime=start_dt,\n",
    "#         n_steps=cfg.steps,\n",
    "#         checkpoint_dir=cfg.checkpoint_dir,\n",
    "#         checkpoint_name=cfg.checkpoint_name,\n",
    "#         init_data_path=cfg.init_data,\n",
    "#         output_path=cfg.output,\n",
    "#         variables=cfg.variables,\n",
    "#         ema=cfg.ema,\n",
    "#     )\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth2studio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
